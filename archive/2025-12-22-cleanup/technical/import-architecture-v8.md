# Import Architecture v8.0 - Simplified P0 Template System

**Last Updated:** 2025-01-12  
**Version:** 8.0 - Simplified Template Auto-Save/Auto-Load Architecture  
**Status:** âœ… Production Ready

---

## ğŸ¯ Executive Summary

### Purpose
Transform diverse supplier data formats (Excel/CSV) into unified `supplier_products` database records with **automatic template management** and **immediate product activation**.

### Key Improvements in v8.0

| Aspect | v6.0 (OLD) | v8.0 (NEW) |
|--------|-----------|-----------|
| **Template Management** | Manual UI, complex mappings | Auto-save/auto-load, P0 only |
| **AI Mapping** | All fields including P0 | P1/P2/P3 only (P0 manual) |
| **Column Mismatch** | No detection | Automatic detection + warning |
| **Template Storage** | All mappings + normalization | P0 mappings + file_columns only |
| **User Action** | Select template manually | Automatic template application |
| **Product Status** | Multi-step activation | Auto-ACTIVE on import |
| **Template Uniqueness** | Name-based | Supplier + Brand unique constraint |

### Architecture Philosophy

**"Zero User Friction for Repetitive Imports"**

1. **First Import:** User maps P0 fields manually â†’ Template auto-saved
2. **Second Import:** Same supplier+brand â†’ Template auto-loaded â†’ P0 pre-filled
3. **Column Change:** Mismatch detected â†’ Warning shown â†’ Re-map â†’ Template updated

---

## ğŸ“¦ High-Level Architecture

### Single-Phase Flow (v8.0)

```mermaid
graph TD
    A[Upload File] --> B[Parse Columns]
    B --> C{Template Exists?}
    
    C -->|Yes + Match| D[Auto-Load Template]
    C -->|Yes + Mismatch| E[Show Warning]
    C -->|No| F[Manual P0 Mapping]
    
    D --> G[Review Mappings]
    E --> F
    F --> G
    
    G --> H[AI Suggests P1/P2/P3]
    H --> I[Create Dataset]
    
    I --> J[Products = ACTIVE]
    J --> K[Auto-Deactivate Old]
    K --> L[Auto-Save/Update Template]
    
    L --> M[âœ… Import Complete]
    
    style D fill:#90EE90
    style E fill:#FFB6C1
    style F fill:#87CEEB
    style J fill:#FFD700
    style L fill:#DDA0DD
```

### Data Flow Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FILE UPLOAD & PARSING                                   â”‚
â”‚ â€¢ User uploads Excel/CSV (max 100MB)                       â”‚
â”‚ â€¢ parse-file-columns: Extract column names                 â”‚
â”‚ â€¢ parse-and-stage-file: Stage all rows                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. TEMPLATE AUTO-LOAD (useAutoImportTemplate)              â”‚
â”‚ â€¢ Query: import_templates WHERE supplier+brand             â”‚
â”‚ â€¢ Check: file_columns match?                               â”‚
â”‚   â”œâ”€ MATCH â†’ Auto-apply P0 mappings âœ…                     â”‚
â”‚   â””â”€ MISMATCH â†’ Show warning + missing/new columns âš ï¸      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. COLUMN MAPPING                                           â”‚
â”‚ â€¢ P0 Fields: Manual dropdown selection (NO AI)             â”‚
â”‚ â€¢ P1/P2/P3 Fields: AI suggestions via ai-suggest-mapping   â”‚
â”‚ â€¢ User reviews/modifies all mappings                        â”‚
â”‚ â€¢ Validation: P0 Field Groups must be complete             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. DATASET CREATION (create-dataset-atomic)                â”‚
â”‚ â€¢ Batch process: 500 rows at a time                        â”‚
â”‚ â€¢ Insert: supplier_products (product_status = 'ACTIVE')    â”‚
â”‚ â€¢ Deactivate: Old products (same supplier+EAN, diff job)   â”‚
â”‚ â€¢ Track: inserted_count, deactivated_count                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. TEMPLATE AUTO-SAVE (save-import-template)               â”‚
â”‚ â€¢ Extract: P0 mappings only from column_mappings           â”‚
â”‚ â€¢ UPSERT: import_templates (unique: supplier+brand)        â”‚
â”‚ â€¢ Update: usage_count++, last_used_at = NOW()              â”‚
â”‚ â€¢ Store: file_columns for mismatch detection               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… RESULT: Products ACTIVE + Template Saved                â”‚
â”‚ â€¢ supplier_products visible in catalog                      â”‚
â”‚ â€¢ Template ready for next import                            â”‚
â”‚ â€¢ User sees: "X producten ACTIEF, Y gedeactiveerd"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Core Components

### 1. Import Template System

#### 1.1 Simplified Template Structure

**Database Table:** `import_templates`

```sql
CREATE TABLE import_templates (
  id SERIAL PRIMARY KEY,
  
  -- Unique key (enforced by constraint)
  supplier_id INTEGER NOT NULL REFERENCES suppliers(id),
  brand_id INTEGER NULL REFERENCES brands(id), -- NULL = "brand from file"
  
  -- P0 mappings only (MVP fields)
  p0_column_mappings JSONB NOT NULL DEFAULT '{}'::jsonb,
  -- Example: { "ean": "EAN-code", "supplier_color_name": "Kleur", ... }
  
  -- Column structure tracking (for mismatch detection)
  file_columns TEXT[] NOT NULL DEFAULT ARRAY[]::text[],
  -- Example: ["EAN-code", "Artikelnaam", "Kleur", "Maat", ...]
  
  -- File metadata
  file_format TEXT NOT NULL, -- 'xlsx', 'csv', 'xls'
  
  -- Usage tracking
  usage_count INTEGER NOT NULL DEFAULT 1,
  last_used_at TIMESTAMP WITH TIME ZONE,
  
  -- Timestamps
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  is_active BOOLEAN NOT NULL DEFAULT true,
  
  -- Unique constraint: 1 active template per supplier+brand
  CONSTRAINT import_templates_supplier_brand_unique 
    UNIQUE (supplier_id, COALESCE(brand_id, -1)) 
    WHERE is_active = true
);

-- Index for fast template lookup
CREATE INDEX idx_import_templates_supplier_brand 
ON import_templates(supplier_id, brand_id) 
WHERE is_active = true;

COMMENT ON TABLE import_templates IS 
  'v8.0 Simplified templates: P0 mappings only, auto-save/auto-load';

COMMENT ON COLUMN import_templates.p0_column_mappings IS 
  'P0 (MVP) field mappings only - handmatig gemapped door gebruiker';
  
COMMENT ON COLUMN import_templates.file_columns IS 
  'Array van originele Excel kolommen voor mismatch detectie bij volgende import';
```

#### 1.2 Template Uniqueness Logic

**Constraint Explanation:**
```sql
CONSTRAINT import_templates_supplier_brand_unique 
  UNIQUE (supplier_id, COALESCE(brand_id, -1)) 
  WHERE is_active = true
```

**Why `COALESCE(brand_id, -1)`?**
- PostgreSQL UNIQUE constraints treat NULL values as distinct
- Without COALESCE: Multiple templates possible with `brand_id = NULL`
- With COALESCE: Only 1 template per `(supplier_id, NULL)` combination
- `-1` is arbitrary (could be any value not used as real brand_id)

**Examples:**
```sql
-- Valid: One template per unique combination
(supplier_id: 5, brand_id: 10)  -- Template A
(supplier_id: 5, brand_id: 20)  -- Template B
(supplier_id: 5, brand_id: NULL) -- Template C (brand from file)

-- Invalid: Duplicate supplier+brand
(supplier_id: 5, brand_id: 10)  -- âŒ Duplicate of Template A
```

#### 1.3 Template Auto-Load Hook

**File:** `src/hooks/use-auto-import-template.ts`

```typescript
export interface SimplifiedImportTemplate {
  id: number;
  supplier_id: number;
  brand_id: number | null; // NULL = brand from file
  p0_column_mappings: Record<string, string>;
  file_columns: string[];
  usage_count: number;
  last_used_at: string | null;
  created_at: string;
  updated_at: string;
  is_active: boolean;
  file_format: string;
}

export interface ColumnMismatch {
  hasMismatch: boolean;
  missingInFile?: string[]; // In template, not in new file
  newInFile?: string[]; // In new file, not in template
}

export function useAutoImportTemplate(
  supplierId: number | null,
  brandId: number | null,
  fileColumns: string[]
) {
  // 1. Fetch template for supplier+brand
  const { data: template } = useQuery({
    queryKey: ['import-template-auto', supplierId, brandId],
    queryFn: async () => {
      if (!supplierId) return null;

      let query = supabase
        .from('import_templates')
        .select('*')
        .eq('supplier_id', supplierId)
        .eq('is_active', true);

      // NULL-safe brand filter
      if (brandId) {
        query = query.eq('brand_id', brandId);
      } else {
        query = query.is('brand_id', null);
      }

      const { data, error } = await query.single();
      return error?.code === 'PGRST116' ? null : data;
    },
    enabled: !!supplierId && fileColumns.length > 0,
  });

  // 2. Check column mismatch
  const columnMismatch: ColumnMismatch = useMemo(() => {
    if (!template || fileColumns.length === 0) {
      return { hasMismatch: false };
    }

    const templateColumns = template.file_columns || [];
    const fileColumnsSet = new Set(fileColumns);
    const templateColumnsSet = new Set(templateColumns);

    const missingInFile = templateColumns.filter(
      col => !fileColumnsSet.has(col)
    );
    const newInFile = fileColumns.filter(
      col => !templateColumnsSet.has(col)
    );

    if (missingInFile.length > 0 || newInFile.length > 0) {
      return { hasMismatch: true, missingInFile, newInFile };
    }

    return { hasMismatch: false };
  }, [template, fileColumns]);

  // 3. Upsert template (called after successful import)
  const upsertTemplate = useMutation({
    mutationFn: async (params: {
      p0Mappings: Record<string, string>;
      fileColumns: string[];
      fileFormat: string;
    }) => {
      // Call save-import-template edge function
      const { data, error } = await supabase.functions.invoke(
        'save-import-template',
        {
          body: {
            supplier_id: supplierId,
            brand_id: brandId,
            p0_mappings: params.p0Mappings,
            file_columns: params.fileColumns,
            file_format: params.fileFormat,
          },
        }
      );
      
      if (error) throw error;
      return data;
    },
  });

  return { template, columnMismatch, upsertTemplate };
}
```

#### 1.4 Column Mismatch Detection Algorithm

**Algorithm:**
```typescript
function detectColumnMismatch(
  templateColumns: string[],
  fileColumns: string[]
): ColumnMismatch {
  const fileSet = new Set(fileColumns);
  const templateSet = new Set(templateColumns);

  // Columns in template but NOT in new file
  const missingInFile = templateColumns.filter(col => !fileSet.has(col));

  // Columns in new file but NOT in template
  const newInFile = fileColumns.filter(col => !templateSet.has(col));

  if (missingInFile.length > 0 || newInFile.length > 0) {
    return {
      hasMismatch: true,
      missingInFile,
      newInFile,
    };
  }

  return { hasMismatch: false };
}
```

**Example Scenarios:**

**Scenario 1: Perfect Match âœ…**
```
Template: ["EAN", "Naam", "Kleur", "Maat"]
New File: ["EAN", "Naam", "Kleur", "Maat"]
Result: { hasMismatch: false }
```

**Scenario 2: Column Renamed âš ï¸**
```
Template: ["EAN", "Naam", "Kleur", "Maat"]
New File: ["EAN", "Artikelnaam", "Kleur", "Maat"]
Result: { 
  hasMismatch: true, 
  missingInFile: ["Naam"], 
  newInFile: ["Artikelnaam"] 
}
```

**Scenario 3: New Column Added âš ï¸**
```
Template: ["EAN", "Naam", "Kleur"]
New File: ["EAN", "Naam", "Kleur", "Maat", "Prijs"]
Result: { 
  hasMismatch: true, 
  missingInFile: [], 
  newInFile: ["Maat", "Prijs"] 
}
```

---

### 2. Edge Functions

#### 2.1 parse-file-columns

**Purpose:** Fast column extraction without full file parsing (preview only)

**Input:**
```typescript
{
  import_job_id: number
}
```

**Process:**
1. Download first 500KB of file from Supabase Storage
2. Detect file format (CSV/Excel)
3. Parse header row only
4. Extract column names + 5 sample values per column
5. Auto-detect delimiter for CSV (`,`, `;`, `\t`)
6. Early EAN checksum validation (if "EAN" column found)
7. Save original column order
8. Update job status to `IMPORT_PENDING`

**Output:**
```typescript
{
  column_names: string[];
  column_samples: Record<string, string[]>; // 5 samples per column
  total_rows: number;
  has_ean_column: boolean;
  ean_validation: {
    valid_count: number;
    invalid_count: number;
    sample_valid: string[];
    sample_invalid: string[];
  } | null;
}
```

**Example Response:**
```json
{
  "column_names": ["EAN", "Artikelnaam", "Kleur", "Maat", "Prijs"],
  "column_samples": {
    "EAN": ["8712345678901", "8712345678918", "8712345678925"],
    "Artikelnaam": ["T-shirt Basic", "Polo Classic", "Hoodie Sport"],
    "Kleur": ["Navy", "Wit", "Zwart"],
    "Maat": ["M", "L", "XL"],
    "Prijs": ["19.95", "24.95", "34.95"]
  },
  "total_rows": 1500,
  "has_ean_column": true,
  "ean_validation": {
    "valid_count": 100,
    "invalid_count": 0,
    "sample_valid": ["8712345678901", "8712345678918"],
    "sample_invalid": []
  }
}
```

**Performance:**
- Time: ~1-3 seconds (only reads first 500KB)
- Memory: ~10MB peak
- Suitable for: Files up to 100MB

---

#### 2.2 parse-and-stage-file

**Purpose:** Full file parsing + staging for dataset creation

**Input:**
```typescript
{
  import_job_id: number
}
```

**Process:**
1. Download full file from Supabase Storage
2. Auto-detect delimiter for CSV (analyze first 10 rows)
3. Parse all rows with Papa Parse (CSV) or SheetJS (Excel)
4. Stage rows in batches of 500 to `supplier_raw_staging` table
5. Track progress: `total_rows`, `staged_rows`, `errors`
6. Update job status to `STAGED`
7. Clean up: Delete file from storage after successful staging

**Output:**
```typescript
{
  import_job_id: number;
  staged_count: number;
  error_count: number;
  total_rows: number;
  column_names: string[];
  elapsed_ms: number;
}
```

**Example Log Output:**
```
ğŸš€ Starting parse-and-stage for job 282
ğŸ“ File: Sixton RoedrinnkCatalog.csv (2.34 MB)
ğŸ“¦ Staging 1690 rows in 4 batches (batch size: 500)...
ğŸ“¦ Staging batch 1/4 (500 rows, 0/1690 total)
ğŸ“¦ Staging batch 2/4 (500 rows, 500/1690 total)
ğŸ“¦ Staging batch 3/4 (500 rows, 1000/1690 total)
ğŸ“¦ Staging batch 4/4 (190 rows, 1500/1690 total)
âœ… Staging complete: 1690/1690 rows staged (0 errors)
âœ… Parse and stage complete: 1690 rows staged in 2234ms
âœ… Background file cleanup succeeded
```

**Performance Characteristics:**
- CSV parsing: ~1000 rows/second
- Excel parsing: ~500 rows/second
- Batch size: 500 rows (balance speed vs memory)
- Memory usage: ~50MB peak (constant, independent of file size)

**Error Handling:**
- Individual row errors: Log but continue (non-blocking)
- Batch errors: Retry up to 3 times with exponential backoff
- Critical errors: Mark job as `FAILED`, preserve staged data

---

#### 2.3 ai-suggest-mapping

**Purpose:** AI-powered column mapping suggestions for **P1/P2/P3 fields ONLY**

**Critical Rule:** P0 fields are **NEVER** suggested by AI. Users map P0 fields manually.

**Input:**
```typescript
{
  import_job_id: number;
  supplier_id: number;
  brand_id: number | null;
  column_names: string[];
  column_samples: Record<string, string[]>;
}
```

**Process:**
1. Fetch PIM field definitions from database
2. **Filter OUT P0 fields:** Remove all P0 priority fields + immutable context fields
3. Build AI prompt with P1/P2/P3 fields only
4. Call Lovable AI (gemini-2.5-flash model)
5. Parse AI response (JSON with field mappings + confidence scores)
6. **Double-check filter:** Remove any P0 fields from AI response (safety)
7. Cache result for 7 days (based on column hash)
8. Return suggestions with confidence scores

**AI System Prompt:**
```
You are a column mapping expert for Product Information Management (PIM) systems.

ğŸš« CRITICAL RULE:
P0 (MVP) fields are mapped MANUALLY by users - you NEVER suggest these fields.

P0 FIELDS TO SKIP (do NOT suggest):
- ean
- supplier_color_name
- supplier_color_code
- supplier_style_name
- supplier_style_code
- supplier_size_code
- tenant_id
- brand_id
- supplier_id

P1/P2/P3 FIELDS YOU CAN SUGGEST:
- product_group (P1)
- price_retail_cents (P1)
- material_composition (P2)
- weight_grams (P2)
- care_instructions (P3)
- certifications (P3)

Your task:
1. Analyze Excel column names and sample data
2. Suggest ONLY P1/P2/P3 field mappings
3. Provide confidence score (0-100) per mapping
4. Explain reasoning for each suggestion

Return JSON:
{
  "suggestions": [
    {
      "excel_column": "Productgroep",
      "suggested_field": "product_group",
      "confidence": 95,
      "reasoning": "Column name matches exactly, samples confirm product categories"
    }
  ]
}
```

**Output:**
```typescript
{
  suggestions: Array<{
    excel_column: string;
    suggested_field: string;
    confidence: number; // 0-100
    reasoning: string;
  }>;
  cache_hit: boolean;
  processing_time_ms: number;
}
```

**Example Response:**
```json
{
  "suggestions": [
    {
      "excel_column": "Productgroep",
      "suggested_field": "product_group",
      "confidence": 95,
      "reasoning": "Direct match - column contains product category names"
    },
    {
      "excel_column": "Materiaal",
      "suggested_field": "material_composition",
      "confidence": 88,
      "reasoning": "Column describes fabric composition (80% cotton, 20% polyester)"
    },
    {
      "excel_column": "Gewicht",
      "suggested_field": "weight_grams",
      "confidence": 92,
      "reasoning": "Numeric values with 'g' suffix, matches weight pattern"
    }
  ],
  "cache_hit": false,
  "processing_time_ms": 1250
}
```

**P0 Field Filtering (Double Safety):**
```typescript
// 1. Filter P0 fields BEFORE AI call
const p0Fields = await getP0FieldKeys(); // From database
const pimFieldsForAI = allPimFields.filter(
  field => !p0Fields.includes(field.field_key)
);

// 2. Filter P0 fields AFTER AI response (safety)
const filteredSuggestions = aiSuggestions.filter(
  s => !p0Fields.includes(s.suggested_field)
);

if (aiSuggestions.length !== filteredSuggestions.length) {
  console.warn('âš ï¸ AI suggested P0 fields (filtered out):', 
    aiSuggestions.length - filteredSuggestions.length
  );
}
```

**Caching Strategy:**
- Cache key: SHA256 hash of column names (sorted)
- TTL: 7 days
- Cache hit rate: ~75% for repeated imports
- Cache table: `ai_mapping_cache`

**Example Log Output:**
```
ğŸ¤– AI analyzing mapping for job 282, supplier 10, brand 70
ğŸ”‘ Cache key generated: e1cf448936232ce8... (from 21 columns)
âœ… Cache HIT! Returning cached mapping from 2025-11-07T09:21:51
ğŸ“Š Cached confidence score: 75/90
âœ… Cache usage stats updated
```

---

#### 2.4 create-dataset-atomic

**Purpose:** Convert staged data to `supplier_products` with auto-activation

**Input:**
```typescript
{
  import_job_id: number;
  column_mapping: Record<string, string>;
  fallback_selections?: Record<string, any>;
}
```

**Process:**

**Step 1: Validation**
- Verify P0 Field Groups complete (Color, Style, Size, EAN)
- Check supplier_id and brand_id set
- Validate column_mapping contains all required P0 fields

**Step 2: Batch Processing**
```typescript
const BATCH_SIZE = 500;
let offset = 0;
let total_inserted = 0;
let total_deactivated = 0;

while (true) {
  // Read batch from supplier_raw_staging
  const batch = await supabase
    .from('supplier_raw_staging')
    .select('*')
    .eq('import_job_id', import_job_id)
    .range(offset, offset + BATCH_SIZE - 1);

  if (batch.length === 0) break;

  // Map columns to PIM fields
  const mapped_products = batch.map(row => 
    mapRawDataToProduct(row, column_mapping, fallback_selections)
  );

  // Insert as ACTIVE products
  const { data: inserted } = await supabase
    .from('supplier_products')
    .insert(mapped_products.map(p => ({
      ...p,
      product_status: 'ACTIVE',
      import_job_id: import_job_id,
    })))
    .select();

  total_inserted += inserted.length;

  // Auto-deactivate old products (same supplier+EAN, different job)
  const eans = inserted.map(p => p.ean).filter(Boolean);
  
  const { data: deactivated } = await supabase
    .from('supplier_products')
    .update({ product_status: 'INACTIVE' })
    .eq('supplier_id', supplier_id)
    .in('ean', eans)
    .neq('import_job_id', import_job_id)
    .eq('product_status', 'ACTIVE')
    .select();

  total_deactivated += deactivated?.length || 0;

  offset += BATCH_SIZE;
}
```

**Step 3: Finalization**
- Update `import_supplier_dataset_jobs`:
  - `inserted_count = total_inserted`
  - `deactivated_count = total_deactivated`
  - `file_status = 'ACTIVE'`
  - `completed_at = NOW()`
- Log errors to `import_job_errors` table

**Output:**
```typescript
{
  import_job_id: number;
  inserted_count: number;
  deactivated_count: number;
  error_count: number;
  elapsed_ms: number;
}
```

**Example Response:**
```json
{
  "import_job_id": 282,
  "inserted_count": 1690,
  "deactivated_count": 847,
  "error_count": 0,
  "elapsed_ms": 8420
}
```

**Auto-Deactivation Logic:**

**Scenario:** Importing newer version of supplier catalog
```sql
-- Before import
supplier_products WHERE supplier_id = 10:
  EAN: 8712345678901, import_job_id: 280, product_status: ACTIVE
  EAN: 8712345678918, import_job_id: 280, product_status: ACTIVE

-- Import job 282 inserts same EANs
INSERT INTO supplier_products (ean, import_job_id, product_status)
VALUES 
  ('8712345678901', 282, 'ACTIVE'),
  ('8712345678918', 282, 'ACTIVE');

-- Auto-deactivation query
UPDATE supplier_products
SET product_status = 'INACTIVE'
WHERE supplier_id = 10
  AND ean IN ('8712345678901', '8712345678918')
  AND import_job_id != 282
  AND product_status = 'ACTIVE';

-- After import
supplier_products WHERE supplier_id = 10:
  EAN: 8712345678901, import_job_id: 280, product_status: INACTIVE (old)
  EAN: 8712345678901, import_job_id: 282, product_status: ACTIVE (new)
  EAN: 8712345678918, import_job_id: 280, product_status: INACTIVE (old)
  EAN: 8712345678918, import_job_id: 282, product_status: ACTIVE (new)
```

**Key Benefits:**
- âœ… Historie behouden (old records not deleted, only deactivated)
- âœ… Automatic replacement (newest import always active)
- âœ… Rollback mogelijk (can re-activate old import if needed)
- âœ… Audit trail (see which job created each product version)

---

#### 2.5 save-import-template (NEW in v8.0)

**Purpose:** Auto-save P0 mappings after successful import

**Input:**
```typescript
{
  supplier_id: number;
  brand_id: number | null;
  p0_mappings: Record<string, string>;
  file_columns: string[];
  file_format: string;
}
```

**Process:**
1. Fetch P0 field keys from database (`pim_field_definitions` WHERE priority = 'P0')
2. Add immutable context fields: `tenant_id`, `brand_id`, `supplier_id`
3. Filter `p0_mappings` to only include P0 fields (safety check)
4. Check existing template for supplier+brand combination
5. **UPSERT:**
   - If exists: UPDATE `p0_column_mappings`, `file_columns`, `usage_count++`, `last_used_at`
   - If not exists: INSERT new template
6. Return template ID and action (created/updated)

**SQL UPSERT Logic:**
```sql
INSERT INTO import_templates (
  supplier_id,
  brand_id,
  p0_column_mappings,
  file_columns,
  file_format,
  usage_count,
  last_used_at,
  is_active
)
VALUES (
  $1, -- supplier_id
  $2, -- brand_id
  $3, -- p0_column_mappings
  $4, -- file_columns
  $5, -- file_format
  1,  -- usage_count
  NOW(), -- last_used_at
  true
)
ON CONFLICT (supplier_id, COALESCE(brand_id, -1))
WHERE is_active = true
DO UPDATE SET
  p0_column_mappings = EXCLUDED.p0_column_mappings,
  file_columns = EXCLUDED.file_columns,
  file_format = EXCLUDED.file_format,
  usage_count = import_templates.usage_count + 1,
  last_used_at = NOW(),
  updated_at = NOW()
RETURNING *;
```

**Output:**
```typescript
{
  template_id: number;
  action: 'created' | 'updated';
  usage_count: number;
}
```

**Example Responses:**

**First Import (Created):**
```json
{
  "template_id": 42,
  "action": "created",
  "usage_count": 1
}
```

**Second Import (Updated):**
```json
{
  "template_id": 42,
  "action": "updated",
  "usage_count": 2
}
```

**P0 Field Filtering:**
```typescript
// Example: User mapped 15 fields, but only 8 are P0
const allMappings = {
  ean: "EAN",
  supplier_color_name: "Kleur",
  supplier_size_code: "Maat",
  supplier_style_name: "Artikelnaam",
  product_group: "Productgroep", // P1 - should be filtered out
  material_composition: "Materiaal", // P2 - should be filtered out
  // ... more fields
};

const p0FieldKeys = [
  'ean', 'supplier_color_name', 'supplier_color_code',
  'supplier_style_name', 'supplier_style_code', 'supplier_size_code',
  'tenant_id', 'brand_id', 'supplier_id'
];

const p0Mappings = Object.fromEntries(
  Object.entries(allMappings).filter(([key]) => 
    p0FieldKeys.includes(key)
  )
);

// Result: Only P0 fields stored in template
// {
//   ean: "EAN",
//   supplier_color_name: "Kleur",
//   supplier_size_code: "Maat",
//   supplier_style_name: "Artikelnaam"
// }
```

**Non-Blocking Execution:**

Template save failures do NOT interrupt user flow:
```typescript
try {
  await saveImportTemplate(params);
  console.log('âœ… Template saved successfully');
} catch (error) {
  // Log error but don't throw - template is convenience feature
  console.error('âš ï¸ Template save failed (non-blocking):', error);
}

// User flow continues regardless of template save result
showSuccessToast(`${inserted_count} producten geÃ¯mporteerd`);
```

---

## ğŸ“Š Database Schema

### Core Tables

#### import_supplier_dataset_jobs

**Purpose:** Track import jobs and their status

```sql
CREATE TABLE import_supplier_dataset_jobs (
  id SERIAL PRIMARY KEY,
  
  -- File metadata
  original_filename TEXT NOT NULL,
  file_name TEXT NOT NULL, -- Supabase Storage path
  file_size_bytes BIGINT,
  original_file_extension TEXT, -- 'xlsx', 'csv', 'xls'
  
  -- Context
  supplier_id INTEGER REFERENCES suppliers(id),
  brand_id INTEGER REFERENCES brands(id),
  tenant_id UUID REFERENCES tenants(id),
  
  -- Status tracking
  file_status TEXT NOT NULL DEFAULT 'UPLOADED'
    CHECK (file_status IN (
      'UPLOADED',       -- File uploaded to storage
      'IMPORT_PENDING', -- Columns parsed, ready for mapping
      'MAPPING',        -- User mapping columns
      'STAGED',         -- Data staged, ready for creation
      'ACTIVE',         -- Dataset created, products active
      'INACTIVE',       -- Dataset deactivated
      'ARCHIVED',       -- Dataset archived
      'ERROR'           -- Error during processing
    )),
  
  -- Import results
  inserted_count INTEGER DEFAULT 0,
  deactivated_count INTEGER DEFAULT 0, -- NEW: Count of auto-deactivated products
  error_count INTEGER DEFAULT 0,
  
  -- Column metadata
  column_names TEXT[], -- Original columns from file
  column_samples JSONB, -- Sample values per column
  
  -- Timestamps
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  completed_at TIMESTAMP WITH TIME ZONE,
  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Indexes
CREATE INDEX idx_import_jobs_supplier ON import_supplier_dataset_jobs(supplier_id);
CREATE INDEX idx_import_jobs_brand ON import_supplier_dataset_jobs(brand_id);
CREATE INDEX idx_import_jobs_status ON import_supplier_dataset_jobs(file_status);
CREATE INDEX idx_import_jobs_tenant ON import_supplier_dataset_jobs(tenant_id);
```

---

#### supplier_raw_staging

**Purpose:** Temporary staging area for raw import data

```sql
CREATE TABLE supplier_raw_staging (
  id BIGSERIAL PRIMARY KEY,
  import_job_id INTEGER NOT NULL REFERENCES import_supplier_dataset_jobs(id) ON DELETE CASCADE,
  
  -- Raw row data
  raw_data JSONB NOT NULL, -- All columns as key-value pairs
  
  -- Row metadata
  row_number INTEGER NOT NULL,
  
  -- Timestamps
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Indexes
CREATE INDEX idx_raw_staging_job ON supplier_raw_staging(import_job_id);
CREATE INDEX idx_raw_staging_job_row ON supplier_raw_staging(import_job_id, row_number);

-- Automatic cleanup (data older than 7 days)
-- Managed by cleanup-old-temp-data edge function (cron daily at 02:00)
```

**Example Row:**
```json
{
  "id": 123456,
  "import_job_id": 282,
  "raw_data": {
    "EAN": "8712345678901",
    "Artikelnaam": "T-shirt Basic Navy",
    "Kleur": "Navy",
    "Maat": "M",
    "Prijs": "19.95"
  },
  "row_number": 1,
  "created_at": "2025-01-12T10:53:45Z"
}
```

---

#### supplier_products

**Purpose:** Final destination for imported products

```sql
CREATE TABLE supplier_products (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  
  -- Import tracking
  import_job_id INTEGER REFERENCES import_supplier_dataset_jobs(id),
  
  -- Context (immutable P0 fields)
  tenant_id UUID NOT NULL REFERENCES tenants(id),
  supplier_id INTEGER NOT NULL REFERENCES suppliers(id),
  brand_id INTEGER REFERENCES brands(id),
  
  -- P0 MVP Fields (Critical for import)
  ean TEXT, -- EAN-13 barcode
  supplier_color_name TEXT,
  supplier_color_code TEXT,
  supplier_style_name TEXT,
  supplier_style_code TEXT,
  supplier_size_code TEXT,
  
  -- P1 Fields (Good to have)
  product_group TEXT,
  price_retail_cents INTEGER,
  price_cost_cents INTEGER,
  
  -- P2 Fields (Better to have)
  material_composition TEXT,
  weight_grams INTEGER,
  image_urls TEXT[],
  
  -- P3 Fields (Best to have)
  care_instructions TEXT,
  certifications TEXT[],
  
  -- Status
  product_status TEXT NOT NULL DEFAULT 'INACTIVE'
    CHECK (product_status IN ('INACTIVE', 'ACTIVE')),
  
  -- Timestamps
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);

-- Indexes
CREATE INDEX idx_supplier_products_status 
  ON supplier_products(product_status);

CREATE INDEX idx_supplier_products_supplier_ean_active 
  ON supplier_products(supplier_id, ean, product_status)
  WHERE product_status = 'ACTIVE';

CREATE INDEX idx_supplier_products_import_job 
  ON supplier_products(import_job_id);

CREATE INDEX idx_supplier_products_tenant 
  ON supplier_products(tenant_id);

-- RLS Policies
ALTER TABLE supplier_products ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view their tenant products"
  ON supplier_products FOR SELECT
  USING (tenant_id = auth.jwt()->>'tenant_id'::uuid);

CREATE POLICY "Admins can manage products"
  ON supplier_products FOR ALL
  TO authenticated
  USING (auth.uid() IN (SELECT user_id FROM user_roles WHERE role = 'admin'))
  WITH CHECK (auth.uid() IN (SELECT user_id FROM user_roles WHERE role = 'admin'));
```

**Key Points:**
- **No UNIQUE constraint on (supplier_id, ean):** Allows multiple versions (historie behoud)
- **Only one ACTIVE per supplier+EAN:** Enforced by application logic, not DB constraint
- **product_status index:** Fast queries for active products only
- **import_job_id tracking:** Know which import created each product

---

## ğŸ¯ User Flow Detailed

### Scenario 1: First Import (No Template)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Upload File                                         â”‚
â”‚ â€¢ User navigates to /import                                 â”‚
â”‚ â€¢ Clicks "Nieuw Bestand Uploaden"                           â”‚
â”‚ â€¢ Selects Excel/CSV file (max 100MB)                        â”‚
â”‚ â€¢ File uploads to Supabase Storage                          â”‚
â”‚ â€¢ Creates import_supplier_dataset_jobs record               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Parse Columns                                       â”‚
â”‚ â€¢ Edge function: parse-file-columns                         â”‚
â”‚ â€¢ Extracts column names + sample values                     â”‚
â”‚ â€¢ EAN checksum validation (if EAN column found)             â”‚
â”‚ â€¢ Updates job: file_status = 'IMPORT_PENDING'               â”‚
â”‚ â€¢ Redirects to: /import/convert?dataset_id={id}             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Convert Page - Select Supplier & Brand             â”‚
â”‚ â€¢ Dropdowns: Supplier (required), Brand (optional)          â”‚
â”‚ â€¢ Brand "Merk uit bestand" option (brand_id = NULL)         â”‚
â”‚ â€¢ Template lookup: useAutoImportTemplate(supplier, brand)   â”‚
â”‚ â€¢ Result: No template found (first time)                    â”‚
â”‚ â€¢ Shows: "Geen template gevonden - Map P0 velden handmatig" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Stage File Data                                     â”‚
â”‚ â€¢ Edge function: parse-and-stage-file                       â”‚
â”‚ â€¢ Parses ALL rows (not just columns)                        â”‚
â”‚ â€¢ Stages to supplier_raw_staging in batches                 â”‚
â”‚ â€¢ Progress bar: "1690 / 1690 rijen verwerkt"                â”‚
â”‚ â€¢ Updates job: file_status = 'STAGED'                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: AI Mapping Suggestions (P1/P2/P3 only)             â”‚
â”‚ â€¢ Edge function: ai-suggest-mapping                         â”‚
â”‚ â€¢ AI analyzes columns (skips P0 fields)                     â”‚
â”‚ â€¢ Returns suggestions for P1/P2/P3 fields only              â”‚
â”‚ â€¢ Shows: Confidence scores per field                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Manual P0 Mapping                                   â”‚
â”‚ â€¢ User sees: P0 fields with dropdown selectors              â”‚
â”‚ â€¢ Required fields marked with red asterisk                  â”‚
â”‚ â€¢ Column samples shown for context                          â”‚
â”‚ â€¢ User maps:                                                â”‚
â”‚   - EAN â†’ "EAN"                                             â”‚
â”‚   - supplier_color_name â†’ "Kleur"                           â”‚
â”‚   - supplier_style_name â†’ "Artikelnaam"                     â”‚
â”‚   - supplier_size_code â†’ "Maat"                             â”‚
â”‚ â€¢ AI suggestions NOT shown for P0 fields                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: Review & Validate                                   â”‚
â”‚ â€¢ Quality score calculated (P0/P1/P2/P3 weighted)           â”‚
â”‚ â€¢ Field Group validation:                                   â”‚
â”‚   âœ… Color Group: supplier_color_name mapped                â”‚
â”‚   âœ… Style Group: supplier_style_name mapped                â”‚
â”‚   âœ… Size Group: supplier_size_code mapped                  â”‚
â”‚   âœ… EAN Group: ean mapped                                  â”‚
â”‚ â€¢ Validation result: "Alle P0 velden compleet" âœ…           â”‚
â”‚ â€¢ Button enabled: "Dataset Aanmaken"                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: Create Dataset                                      â”‚
â”‚ â€¢ Edge function: create-dataset-atomic                      â”‚
â”‚ â€¢ Processes in batches (500 rows)                           â”‚
â”‚ â€¢ Inserts supplier_products (product_status = 'ACTIVE')     â”‚
â”‚ â€¢ Auto-deactivates old products (same supplier+EAN)         â”‚
â”‚ â€¢ Progress: "1690 / 1690 producten verwerkt"                â”‚
â”‚ â€¢ Result: inserted=1690, deactivated=0 (first import)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 9: Auto-Save Template                                  â”‚
â”‚ â€¢ Edge function: save-import-template                       â”‚
â”‚ â€¢ Filters P0 mappings only:                                 â”‚
â”‚   {                                                         â”‚
â”‚     ean: "EAN",                                             â”‚
â”‚     supplier_color_name: "Kleur",                           â”‚
â”‚     supplier_style_name: "Artikelnaam",                     â”‚
â”‚     supplier_size_code: "Maat"                              â”‚
â”‚   }                                                         â”‚
â”‚ â€¢ Saves file_columns: ["EAN", "Kleur", "Artikelnaam", ...] â”‚
â”‚ â€¢ Result: template_id=42, action='created', usage_count=1   â”‚
â”‚ â€¢ Silent operation (non-blocking, no UI feedback)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… SUCCESS                                                  â”‚
â”‚ â€¢ Toast: "âœ… 1690 producten geÃ¯mporteerd"                   â”‚
â”‚ â€¢ Products immediately visible in /supplier-catalog         â”‚
â”‚ â€¢ Template saved for next import (invisible to user)        â”‚
â”‚ â€¢ file_status = 'ACTIVE'                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Scenario 2: Second Import (Template Match)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEPS 1-3: Same as First Import                            â”‚
â”‚ â€¢ Upload file                                               â”‚
â”‚ â€¢ Parse columns                                             â”‚
â”‚ â€¢ Select supplier & brand                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Template Auto-Load âœ¨                              â”‚
â”‚ â€¢ Query: import_templates                                   â”‚
â”‚   WHERE supplier_id = 10 AND brand_id = 70                  â”‚
â”‚ â€¢ Template found: id=42, usage_count=1                      â”‚
â”‚ â€¢ Column match check:                                       â”‚
â”‚   template.file_columns = ["EAN", "Kleur", "Artikelnaam"]  â”‚
â”‚   new_file.columns = ["EAN", "Kleur", "Artikelnaam"]       â”‚
â”‚ â€¢ Result: PERFECT MATCH âœ…                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Auto-Apply Mappings ğŸš€                             â”‚
â”‚ â€¢ P0 mappings automatically applied:                        â”‚
â”‚   ean â†’ "EAN"                                               â”‚
â”‚   supplier_color_name â†’ "Kleur"                             â”‚
â”‚   supplier_style_name â†’ "Artikelnaam"                       â”‚
â”‚   supplier_size_code â†’ "Maat"                               â”‚
â”‚ â€¢ Green alert shown:                                        â”‚
â”‚   "âœ… Template toegepast"                                   â”‚
â”‚   "Template voor Supplier A Ã— Brand B"                      â”‚
â”‚   "Laatst gebruikt: 2 dagen geleden"                        â”‚
â”‚   "2 keer gebruikt"                                         â”‚
â”‚ â€¢ User can directly proceed to validation step              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEPS 6-8: Same as First Import                            â”‚
â”‚ â€¢ Stage file data                                           â”‚
â”‚ â€¢ AI mapping (P1/P2/P3 only)                                â”‚
â”‚ â€¢ Validate & create dataset                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 9: Update Template                                     â”‚
â”‚ â€¢ Edge function: save-import-template                       â”‚
â”‚ â€¢ UPSERT: Updates existing template (id=42)                 â”‚
â”‚ â€¢ Increments: usage_count = 2 â†’ 3                           â”‚
â”‚ â€¢ Updates: last_used_at = NOW()                             â”‚
â”‚ â€¢ Result: template_id=42, action='updated', usage_count=3   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… SUCCESS                                                  â”‚
â”‚ â€¢ Toast: "âœ… 1850 producten geÃ¯mporteerd, 1690 gedeactiveerd"â”‚
â”‚ â€¢ Products visible in /supplier-catalog                     â”‚
â”‚ â€¢ Old products (import job 282) now INACTIVE                â”‚
â”‚ â€¢ Template ready for next import (usage_count=3)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Scenario 3: Column Mismatch

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEPS 1-3: Same as Previous Scenarios                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Template Lookup + Mismatch Detection âš ï¸            â”‚
â”‚ â€¢ Template found: id=42                                     â”‚
â”‚ â€¢ Column comparison:                                        â”‚
â”‚   template: ["EAN", "Naam", "Kleur", "Maat"]               â”‚
â”‚   new file: ["EAN", "Artikelnaam", "Kleur", "Maat", "Prijs"]â”‚
â”‚ â€¢ Mismatch detected:                                        â”‚
â”‚   missing_in_file: ["Naam"]                                 â”‚
â”‚   new_in_file: ["Artikelnaam", "Prijs"]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Show Mismatch Warning                              â”‚
â”‚ â€¢ Red alert displayed:                                      â”‚
â”‚   "âš ï¸ Kolommen komen niet overeen met template"            â”‚
â”‚                                                             â”‚
â”‚   Ontbrekend in nieuw bestand:                              â”‚
â”‚   â€¢ Naam                                                    â”‚
â”‚                                                             â”‚
â”‚   Nieuw in bestand:                                         â”‚
â”‚   â€¢ Artikelnaam                                             â”‚
â”‚   â€¢ Prijs                                                   â”‚
â”‚                                                             â”‚
â”‚   ğŸ” Je moet de P0 velden opnieuw handmatig mappen.        â”‚
â”‚   De template wordt automatisch bijgewerkt na succesvolle  â”‚
â”‚   import.                                                   â”‚
â”‚ â€¢ Template NOT auto-applied                                 â”‚
â”‚ â€¢ User forced to manual mapping                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Manual Re-Mapping                                  â”‚
â”‚ â€¢ User maps P0 fields with new column names:                â”‚
â”‚   ean â†’ "EAN"                                               â”‚
â”‚   supplier_color_name â†’ "Kleur"                             â”‚
â”‚   supplier_style_name â†’ "Artikelnaam" (was "Naam")         â”‚
â”‚   supplier_size_code â†’ "Maat"                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEPS 7-9: Same as Previous Scenarios                      â”‚
â”‚ â€¢ Create dataset                                            â”‚
â”‚ â€¢ Template updated with NEW column structure:               â”‚
â”‚   file_columns: ["EAN", "Artikelnaam", "Kleur", ...]       â”‚
â”‚   p0_mappings: { supplier_style_name: "Artikelnaam" }      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… SUCCESS                                                  â”‚
â”‚ â€¢ Next import with same structure will auto-apply again     â”‚
â”‚ â€¢ Template now reflects NEW file structure                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testing Scenarios

### Test Case 1: First Import (New Template)

**Given:**
- User uploads Excel for Supplier A Ã— Brand B (first time)
- File columns: `["EAN", "Artikelnaam", "Kleur", "Maat"]`

**When:**
- Step 2 (Mapping) loads

**Then:**
- âœ… No template found
- âœ… User must manually map P0 fields
- âœ… AI suggests NO P0 fields (only P1/P2/P3)
- âœ… After successful import:
  - Template auto-saved with:
    - `supplier_id = A`
    - `brand_id = B`
    - `p0_column_mappings = { ean: "EAN", supplier_style_name: "Artikelnaam", ... }`
    - `file_columns = ["EAN", "Artikelnaam", "Kleur", "Maat"]`

**Verification:**
```sql
SELECT * FROM import_templates 
WHERE supplier_id = A AND brand_id = B;
-- Expected: 1 row, usage_count = 1
```

---

### Test Case 2: Repeat Import (Matching Columns)

**Given:**
- Supplier A Ã— Brand B has template
- Template `file_columns = ["EAN", "Artikelnaam", "Kleur", "Maat"]`
- New Excel has EXACT same columns

**When:**
- Step 2 (Mapping) loads

**Then:**
- âœ… Template automatically found
- âœ… `columnMismatch.hasMismatch = false`
- âœ… P0 mappings automatically pre-filled
- âœ… User can skip to validation
- âœ… Template `usage_count` increments after import
- âœ… Green alert: "Template toegepast âœ…"

**Verification:**
```sql
SELECT usage_count, last_used_at 
FROM import_templates 
WHERE supplier_id = A AND brand_id = B;
-- Expected: usage_count = 2, last_used_at = NOW()
```

---

### Test Case 3: Column Mismatch

**Given:**
- Supplier A Ã— Brand B template: `["EAN", "Naam", "Kleur"]`
- New Excel: `["EAN", "Product", "Kleur", "Maat"]`

**When:**
- Step 2 (Mapping) loads

**Then:**
- âœ… Template found
- âœ… `columnMismatch.hasMismatch = true`
- âœ… `columnMismatch.missingInFile = ["Naam"]`
- âœ… `columnMismatch.newInFile = ["Product", "Maat"]`
- âœ… Red alert shown: "âš ï¸ Kolommen komen niet overeen"
- âœ… User must re-map P0 fields manually
- âœ… After import: template updated with NEW file_columns

**Verification:**
```sql
SELECT file_columns FROM import_templates 
WHERE supplier_id = A AND brand_id = B;
-- Expected: ["EAN", "Product", "Kleur", "Maat"]
```

---

### Test Case 4: Brand from File

**Given:**
- User selects "Merk uit bestand" (`brand_id = NULL`)

**When:**
- Template lookup

**Then:**
- âœ… Query: `WHERE supplier_id = X AND brand_id IS NULL`
- âœ… Unique constraint key: `(supplier_id, COALESCE(brand_id, -1))`
- âœ… Template key display: "Supplier A Ã— -"

**Verification:**
```sql
SELECT * FROM import_templates 
WHERE supplier_id = X AND brand_id IS NULL;
-- Expected: 1 row (not multiple)
```

---

### Test Case 5: Template Uniqueness

**Given:**
- Supplier A Ã— Brand B already has ACTIVE template

**When:**
- Second import with same combination
- Template save after import

**Then:**
- âœ… UPSERT works: existing template updated (no duplicate)
- âœ… `usage_count` incremented
- âœ… `file_columns` updated to new values
- âœ… Unique constraint prevents duplicates

**Verification:**
```sql
SELECT COUNT(*) FROM import_templates 
WHERE supplier_id = A AND brand_id = B AND is_active = true;
-- Expected: 1 (not 2!)
```

---

### Test Case 6: AI P0 Field Filtering

**Given:**
- Excel with columns that resemble P0 fields

**When:**
- AI analyze is called

**Then:**
- âœ… Edge function receives P0 field list
- âœ… AI prompt says: "SKIP P0 fields"
- âœ… Response contains NO suggestions for P0 fields
- âœ… Frontend displays only P1/P2/P3 AI suggestions

**Verification:**
```javascript
console.log('AI suggestions:', aiSuggestions);
// Expected: No suggestions with suggested_field = 'ean' / 'supplier_style_name' etc.
```

---

### Test Case 7: Auto-Deactivation

**Given:**
- Import job 280: 100 products (EANs: 001-100), status ACTIVE
- Import job 282: 100 products (EANs: 001-100), same supplier

**When:**
- Job 282 completes

**Then:**
- âœ… Job 282 products: status = ACTIVE
- âœ… Job 280 products (same EANs): status = INACTIVE
- âœ… `deactivated_count = 100` in job 282
- âœ… Historie behouden (old records NOT deleted)

**Verification:**
```sql
-- Job 282 products should be active
SELECT COUNT(*) FROM supplier_products 
WHERE import_job_id = 282 AND product_status = 'ACTIVE';
-- Expected: 100

-- Job 280 products should be inactive
SELECT COUNT(*) FROM supplier_products 
WHERE import_job_id = 280 AND product_status = 'INACTIVE';
-- Expected: 100
```

---

### Test Case 8: Template File Format Detection

**Given:**
- User uploads `.xlsx` file

**When:**
- Template is saved

**Then:**
- âœ… `file_format = 'xlsx'` (detected from extension)

**Verification:**
```sql
SELECT file_format FROM import_templates 
WHERE supplier_id = X AND brand_id = Y;
-- Expected: 'xlsx'
```

---

## ğŸš€ Performance & Scalability

### Performance Benchmarks

| Operation | File Size | Rows | Time | Memory |
|-----------|-----------|------|------|--------|
| Parse columns only | 2.5 MB | 1,690 | ~1s | ~10 MB |
| Parse + stage | 2.5 MB | 1,690 | ~2.2s | ~50 MB |
| Create dataset | - | 1,690 | ~8s | ~80 MB |
| **Total import** | **2.5 MB** | **1,690** | **~11s** | **~80 MB** |
| Parse + stage | 10 MB | 10,000 | ~12s | ~50 MB |
| Create dataset | - | 10,000 | ~45s | ~80 MB |
| **Total import** | **10 MB** | **10,000** | **~57s** | **~80 MB** |

### Scaling Characteristics

**Linear Scaling:**
- Processing time scales linearly with row count
- Memory usage constant (~50-80MB) regardless of file size
- Batch processing prevents memory overflow

**Bottlenecks:**
- Network latency (Supabase Storage download)
- Database write throughput (500 rows/batch optimized)
- AI mapping (cached after first call)

**Optimization Strategies:**
1. **Batch size tuning:** 500 rows balances speed vs memory
2. **AI caching:** 7-day TTL reduces API calls
3. **Parallel batch inserts:** Future improvement (not implemented)
4. **Index optimization:** Composite indexes on supplier+EAN+status

---

## ğŸ” Security Considerations

### Row Level Security (RLS)

**import_templates:**
```sql
-- Only authenticated users can view their own templates
CREATE POLICY "Users can view their templates"
  ON import_templates FOR SELECT
  TO authenticated
  USING (true); -- All authenticated users can see all templates

-- Only admins can modify templates
CREATE POLICY "Admins can manage templates"
  ON import_templates FOR ALL
  TO authenticated
  USING (auth.uid() IN (SELECT user_id FROM user_roles WHERE role = 'admin'))
  WITH CHECK (auth.uid() IN (SELECT user_id FROM user_roles WHERE role = 'admin'));
```

**supplier_products:**
```sql
-- Users can only see products from their tenant
CREATE POLICY "Users can view their tenant products"
  ON supplier_products FOR SELECT
  USING (tenant_id = auth.jwt()->>'tenant_id'::uuid);

-- Only admins can modify products
CREATE POLICY "Admins can manage products"
  ON supplier_products FOR ALL
  TO authenticated
  USING (auth.uid() IN (SELECT user_id FROM user_roles WHERE role = 'admin'))
  WITH CHECK (auth.uid() IN (SELECT user_id FROM user_roles WHERE role = 'admin'));
```

### Edge Function Authorization

All edge functions require authentication:
```typescript
const authHeader = req.headers.get('Authorization');
if (!authHeader) {
  return new Response('Unauthorized', { status: 401 });
}

const supabase = createClient(
  Deno.env.get('SUPABASE_URL')!,
  Deno.env.get('SUPABASE_ANON_KEY')!,
  { global: { headers: { Authorization: authHeader } } }
);

const { data: { user }, error } = await supabase.auth.getUser();
if (error || !user) {
  return new Response('Unauthorized', { status: 401 });
}
```

### Data Validation

**Input Sanitization:**
- All user inputs validated with Zod schemas
- SQL injection prevented (Supabase query builder, no raw SQL)
- File size limits enforced (max 100MB)
- File type validation (only .xlsx, .xls, .csv)

**EAN Validation:**
- Checksum validation during parse
- Invalid EANs logged but don't block import
- Sample invalid EANs shown to user

---

## ğŸ“ˆ Monitoring & Observability

### Key Metrics

**Import Success Rate:**
```sql
SELECT 
  COUNT(*) FILTER (WHERE file_status = 'ACTIVE') as successful,
  COUNT(*) FILTER (WHERE file_status = 'ERROR') as failed,
  COUNT(*) as total,
  ROUND(100.0 * COUNT(*) FILTER (WHERE file_status = 'ACTIVE') / COUNT(*), 2) as success_rate
FROM import_supplier_dataset_jobs
WHERE created_at > NOW() - INTERVAL '7 days';
```

**Template Usage:**
```sql
SELECT 
  supplier_id,
  brand_id,
  usage_count,
  last_used_at,
  DATE_PART('day', NOW() - last_used_at) as days_since_last_use
FROM import_templates
WHERE is_active = true
ORDER BY usage_count DESC
LIMIT 10;
```

**Average Import Duration:**
```sql
SELECT 
  AVG(EXTRACT(EPOCH FROM (completed_at - created_at))) as avg_duration_seconds,
  AVG(inserted_count) as avg_products_inserted
FROM import_supplier_dataset_jobs
WHERE file_status = 'ACTIVE'
  AND completed_at IS NOT NULL
  AND created_at > NOW() - INTERVAL '30 days';
```

### Error Tracking

**Import Job Errors:**
```sql
SELECT 
  import_job_id,
  COUNT(*) as error_count,
  STRING_AGG(DISTINCT error_message, ', ') as error_types
FROM import_job_errors
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY import_job_id
ORDER BY error_count DESC
LIMIT 20;
```

---

## ğŸ”„ Migration from v6.0 to v8.0

### Breaking Changes

1. **Template Structure:**
   - v6.0: `column_mappings` (all fields)
   - v8.0: `p0_column_mappings` (P0 only)

2. **Template Management:**
   - v6.0: Manual UI with template selection
   - v8.0: Auto-save/auto-load (no UI)

3. **AI Mapping:**
   - v6.0: AI suggests all fields
   - v8.0: AI only suggests P1/P2/P3

4. **Product Activation:**
   - v6.0: Manual activation step
   - v8.0: Auto-ACTIVE on import

### Migration SQL

**Executed:** 2025-01-12

```sql
-- Add new columns
ALTER TABLE import_templates 
ADD COLUMN IF NOT EXISTS p0_column_mappings JSONB DEFAULT '{}'::jsonb,
ADD COLUMN IF NOT EXISTS file_columns TEXT[] DEFAULT ARRAY[]::text[];

-- Extract P0 mappings from existing column_mappings
WITH p0_fields AS (
  SELECT field_key 
  FROM pim_field_definitions 
  WHERE priority = 'P0' AND is_active = true
)
UPDATE import_templates it
SET p0_column_mappings = (
  SELECT jsonb_object_agg(key, value)
  FROM jsonb_each_text(it.column_mappings) AS kv(key, value)
  WHERE key IN (SELECT field_key FROM p0_fields)
        OR key IN ('tenant_id', 'brand_id', 'supplier_id')
);

-- Make supplier_id NOT NULL
ALTER TABLE import_templates 
ALTER COLUMN supplier_id SET NOT NULL;

-- Add unique constraint
CREATE UNIQUE INDEX IF NOT EXISTS import_templates_supplier_brand_unique
ON import_templates(supplier_id, COALESCE(brand_id, -1))
WHERE is_active = true;

-- Deprecate old columns
COMMENT ON COLUMN import_templates.column_mappings IS 
  'DEPRECATED: gebruik p0_column_mappings. Legacy: bevat P0+P1+P2+P3';
```

---

## ğŸ“š Related Documentation

- **Progressive Quality Ladder:** `docs/technical/progressive-quality-ladder.md`
- **Field Group Validation:** `docs/technical/field-group-validation.md`
- **AI Mapping System:** `docs/technical/ai-mapping-system.md`
- **Database Schema:** `docs/technical/database-schema.md`
- **User Guide (NL):** `docs/gebruikershandleiding/03-import-proces/`

---

## ğŸ†˜ Troubleshooting

### Issue: Template not auto-loading

**Symptoms:**
- Second import doesn't show green "Template toegepast" alert
- P0 fields not pre-filled

**Diagnosis:**
```sql
-- Check if template exists
SELECT * FROM import_templates 
WHERE supplier_id = ? AND brand_id = ?;

-- Check column match
SELECT file_columns FROM import_templates WHERE id = ?;
-- Compare with new file columns
```

**Solution:**
- Verify supplier+brand IDs match exactly
- Check file_columns array matches new file structure
- If mismatch: re-map P0 fields (template will update)

---

### Issue: AI suggesting P0 fields

**Symptoms:**
- AI suggestions include fields like "ean", "supplier_style_name"

**Diagnosis:**
```typescript
console.log('AI suggestions:', aiSuggestions);
// Check if any suggested_field is in P0 list
```

**Solution:**
- Edge function should filter P0 fields BEFORE and AFTER AI call
- Check `ai-suggest-mapping/index.ts` filter logic
- Verify `pim_field_definitions` table has correct priority values

---

### Issue: Products not auto-deactivating

**Symptoms:**
- Multiple ACTIVE products with same supplier+EAN

**Diagnosis:**
```sql
SELECT 
  ean, 
  import_job_id, 
  product_status,
  created_at
FROM supplier_products
WHERE supplier_id = ? AND ean = ?
ORDER BY created_at DESC;
```

**Solution:**
- Check `create-dataset-atomic` deactivation query
- Verify index exists: `idx_supplier_products_supplier_ean_active`
- Ensure import_job_id is different between imports

---

## ğŸ¯ Success Metrics

### Template System Effectiveness

**Target:** 80% auto-apply rate for repeat imports

```sql
SELECT 
  COUNT(*) FILTER (WHERE template_auto_applied = true) as auto_applied,
  COUNT(*) as total,
  ROUND(100.0 * COUNT(*) FILTER (WHERE template_auto_applied = true) / COUNT(*), 2) as auto_apply_rate
FROM import_supplier_dataset_jobs
WHERE created_at > NOW() - INTERVAL '30 days'
  AND supplier_id IN (
    SELECT supplier_id FROM import_supplier_dataset_jobs 
    GROUP BY supplier_id HAVING COUNT(*) > 1
  );
```

### User Time Savings

**Estimated time savings per import:**
- Manual P0 mapping: ~3 minutes
- Template auto-apply: ~10 seconds
- **Savings: ~2.5 minutes per repeat import**

**Projected monthly savings:**
- Avg repeat imports: 50/month
- Total time saved: 50 Ã— 2.5 = 125 minutes (~2 hours/month)

---

**Last Updated:** 2025-01-12  
**Version:** 8.0  
**Status:** âœ… Production Ready  
**Next Review:** 2025-04-01
